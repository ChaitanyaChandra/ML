{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13360758,"sourceType":"datasetVersion","datasetId":7769196}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chaitanyachandra/08-ml-r-squared-regression-model-selection?scriptVersionId=268396861\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# R² (R-squared) — Coefficient of Determination\n\n\n\n## Concept\n\n**Goal:**\nTo measure **how well a regression model fits** the actual data — i.e., how much of the variation in the target variable $( y )$ is explained by your model.\n\n\n\n## Explanation\n\n### 1. Two Situations to Compare\n\n\n1. **Regression line** → a line fitted by the model (using ordinary least squares).\n2. **Average line** → a horizontal line at the mean of all $( y )$-values.\n\n\n\n### 2. Residual Sum of Squares (SSR or RSS)\n\nWhen you draw the **regression line**, you measure how far each real data point $( y_i )$ is from the predicted point $( \\hat{y}_i )$ on the line.\n\n$SS_{res} = \\sum (y_i - \\hat{y}_i)^2$\n\n✅ This tells you how much **error** (unexplained variance) your model still has after fitting.\n\n\n\n### 3. Total Sum of Squares (SST)\n\nNow imagine no model at all — just an **average line** through the mean of all $( y )$-values $(( \\bar{y} ))$.\n\n$\nSS_{tot} = \\sum (y_i - \\bar{y})^2\n$\n\n✅ This shows **total variation** in the data — how much all $( y_i )$ values differ from their average.\n\n\n\n### 4. Formula for R²\n\n$\nR^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n$\n\n\n\n### 5. Intuition\n\n* If your regression line fits well → $( SS_{res} )$ is **small**, so $( R^2 )$ is **close to 1** ✅\n* If your regression line fits poorly → $( SS_{res} )$ is **large**, so $( R^2 )$ is **close to 0** ❌\n\n\n\n### 6. Typical R² Values and Interpretation\n\n| R² Value      | Interpretation                                                                     |\n| - | - |\n| **1.0**       | Perfect fit — model predicts every point exactly (almost impossible in real data). |\n| **0.9**       | Excellent fit — model explains 90% of data variation.                              |\n| **0.7 – 0.9** | Good fit — quite reliable.                                                         |\n| **0.4 – 0.7** | Weak fit — model misses a lot of variation.                                        |\n| **< 0.4**     | Poor fit — not a good model.                                                       |\n| **< 0**       | Model is worse than just using the mean — model is *nonsense* for this data.       |\n\n\n\n### 8. Summary\n\n> R² tells you **how much better your model is than just predicting the average** every time.\n\nIf your model doesn’t improve much over just using the mean, R² will be low.\nIf it explains most of the variation, R² will be high.\n\n---\n\n## Adjusted R² (Adjusted R Squared)\n\n### Definition\n\n**Adjusted R²** is a modified version of **R² (Coefficient of Determination)** that adjusts for the number of independent variables in a regression model.\nIt penalizes the model for adding unnecessary variables that do not significantly improve the prediction.\n\n\n\n## ⚠️ Problem with R²\n\nWhen you **add more variables** (X₃, X₄, etc.) to a regression model:\n\n* The **total sum of squares (SSₜₒₜ)** remains the same (it depends only on actual y values).\n* The **residual sum of squares (SSᵣₑₛ)** **can only decrease or stay the same** because:\n\n  * The **Ordinary Least Squares (OLS)** method minimizes SSᵣₑₛ.\n  * If the new variable helps, SSᵣₑₛ decreases.\n  * If it doesn’t help, OLS sets its coefficient (b₃) to **zero**, keeping SSᵣₑₛ unchanged.\n* Therefore, **R² never decreases**, even if the new variable is useless.\n\n🧠 **Result:**\nYou might end up with a model that includes unnecessary variables just because R² keeps increasing.\n\n\n## 💡 Solution: Adjusted R²\n\n### Formula\n\n$\n\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - k - 1} \\right)\n$\n\nWhere:\n\n* **n** = Number of observations (sample size)\n* **k** = Number of independent variables\n\n\n### How It Works\n\n* As **k (number of predictors)** increases, the **denominator** ((n - k - 1)) decreases.\n* This makes the ratio larger → leading to **lower Adjusted R²**.\n* Therefore, **Adjusted R² penalizes** adding variables that don’t significantly improve the model.\n\n\n### Key Insight\n\n* Adding a new variable will **only increase Adjusted R²** if the variable provides a **meaningful improvement** in prediction.\n* If it doesn’t, Adjusted R² will **decrease** — discouraging overfitting.\n\n\n##  Summary\n\n| Concept           | Description                                                                                                |\n| ----------------- | ---------------------------------------------------------------------------------------------------------- |\n| **R²**            | Measures model fit — how much of y’s variation is explained by x’s.                                        |\n| **Issue with R²** | Always increases when new variables are added, even useless ones.                                          |\n| **Adjusted R²**   | Adds a penalty for adding variables — increases only if the new variable significantly improves model fit. |\n| **Purpose**       | Helps build parsimonious (simple but effective) models.                                                    |\n\n\n## Intuitive Understanding\n\n* R² = “How well are we fitting the data?”\n* Adjusted R² = “How well are we fitting the data **without overcomplicating** the model?”\n\n---\n\n\n### **Solve:**\n\nYou are given an [Energy.csv dataset](https://www.kaggle.com/datasets/chaitanyachandra/data-csv?select=Energy.csv)  dataset containing several independent features (e.g., temperature, pressure, etc.) and one dependent variable (Energy Output).\n\nYour task is to compare different regression models and evaluate their performance.\n\n\n### **Tasks:**\n\n1. **Load and explore** the dataset from [Energy.csv dataset](https://www.kaggle.com/datasets/chaitanyachandra/data-csv?select=Energy.csv).\n2. **Split** the dataset into training and testing sets (80% train, 20% test).\n3. Train the following regression models:\n\n   * **Linear Regression**\n   * **Polynomial Regression (degree = 4)**\n   * **Support Vector Regression (RBF kernel)**\n   * **Decision Tree Regression**\n   * **Random Forest Regression (n_estimators = 100)**\n4. For **Support Vector Regression**, make sure to:\n   * Apply **feature scaling** to both the independent and dependent variables.\n   * **Inverse transform** predictions to their original scale.\n5. Compute the **R² score** for each model and store the results in a dictionary named `scores`.\n6. **Plot a bar chart** comparing the R² scores of all models.\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# import packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import r2_score\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import  DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# variables\nscores = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# read CSV\ndata = pd.read_csv(\"/kaggle/input/data-csv/Energy.csv\")\ndata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split dependent and independent cells\nindependent_x = data.iloc[:, :-1].values\ndependent_y = data.iloc[:, -1].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split train and test data \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(independent_x, dependent_y, random_state=0, test_size=0.2)\n\nx_train, x_test, y_train, y_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Multi-Linear regression \nlr = LinearRegression()\nlr.fit(x_train, y_train)\nscores[\"Linear\"] = r2_score(y_test, lr.predict(x_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Polynomial Linear Regression\npr = PolynomialFeatures(degree=4)\nlr2 = LinearRegression()\nlr2.fit(pr.fit_transform(x_train), y_train)\nscores[\"Polynomial\"] = r2_score(y_test, lr2.predict(pr.transform(x_test)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Support Vector Regression\nsc_x = StandardScaler()\nsc_y = StandardScaler()\n\nx_train_sc = sc_x.fit_transform(x_train)                   \nx_test_sc  = sc_x.transform(x_test)                      \n\ny_train_2d = np.asarray(y_train).reshape(-1, 1)             \ny_train_sc = sc_y.fit_transform(y_train_2d).ravel()      \n\nsvm = SVR(kernel='rbf')                                     \nsvm.fit(x_train_sc, y_train_sc)                             \n\ny_pred_sc = svm.predict(x_test_sc)                          \ny_pred = sc_y.inverse_transform(y_pred_sc.reshape(-1,1)).ravel()  \n\nscores[\"Support Vector\"] = r2_score(y_test, y_pred) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Decision Tree Regression\ndt = DecisionTreeRegressor()\ndt.fit(x_train, y_train)\nscores[\"Decision Tree\"] = r2_score(y_test, dt.predict(x_test)) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random Forest Regression\nrfr = RandomForestRegressor(random_state=0, n_estimators=10)\nrfr.fit(x_train, y_train)\nscores[\"Random Forest\"] = r2_score(y_test, rfr.predict(x_test)) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scores","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = list(scores.keys())\nvalues = list(scores.values())\n\n# Plot\nplt.figure(figsize=(8,5))\nplt.bar(models, values, color='skyblue')\nplt.title('Model Performance Comparison')\nplt.ylabel('R² Score')\nplt.xticks(rotation=20, ha='right')\nplt.ylim(0.9, 1)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}